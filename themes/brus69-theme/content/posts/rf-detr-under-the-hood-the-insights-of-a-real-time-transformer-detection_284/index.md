---
title: "Радиочастотный ДЕТЕКТОР под капотом: Возможности обнаружения трансформаторов в режиме реального времени | На пути к науке о данных"
date: "2025-11-19T23:13:09+0000"
draft: true
description: ""
h1: "Радиочастотный ДЕТЕКТОР под капотом: Основные возможности обнаружения трансформатора в режиме реального времени"
urldel: "https://towardsdatascience.com/rf-detr-under-the-hood-the-insights-of-a-real-time-transformer-detection/"
---

### Мир компьютерного зрения: знакомство с RF-DETR

Вы, вероятно, слышали о RF-DETR — новой модели обнаружения объектов в реальном времени от Roboflow. Она стала новым SOTA (state-of-the-art) благодаря впечатляющим результатам. Но чтобы по-настоящему понять, что делает её уникальной, нужно взглянуть не только на бенчмарки и погрузиться в её архитектурную ДНК.

RF-DETR — не совсем новое изобретение; её история — это увлекательное путешествие по решению одной проблемы за раз, начиная с фундаментального ограничения в оригинальном DETR и заканчивая лёгким трансформатором для реального времени. Давайте проследим эту эволюцию.

#### Парадигмальный сдвиг в конвейерах обнаружения

В 2020 году появился DETR (DEtection TRansformer) [1], модель, которая полностью изменила конвейер обнаружения объектов. Это был первый полностью сквозной детектор, устранивший необходимость в ручных компонентах, таких как генерация якорей и подавление немаксимумов (NMS). Он достиг этого, объединив CNN-бэкенд с архитектурой энкодера-декодера Transformer. Несмотря на революционный дизайн, у оригинального DETR были существенные проблемы:

1. **Чрезвычайно медленная сходимость:** DETR требовал огромного количества эпох обучения для сходимости, что было в 10–20 раз медленнее, чем у моделей типа Faster R-CNN.
2. **Высокая вычислительная сложность:** механизм внимания в энкодере Transformer имеет сложность O(H2W2C) по отношению к пространственным размерам (H, W) карты признаков. Эта квадратичная сложность делала обработку карт признаков высокого разрешения непозволительно дорогой.
3. **Низкая производительность при обнаружении мелких объектов:** из-за высокой сложности DETR не мог использовать карты признаков высокого разрешения, которые имеют решающее значение для обнаружения мелких объектов.

Эти проблемы были связаны с тем, как механизм внимания Transformer обрабатывал функции изображения, просматривая каждый пиксель, что было неэффективно и сложно для обучения.

#### Прорыв: Deformable DETR

Чтобы решить проблемы DETR, исследователи обратились к **Deformable Convolutional Networks**[2]. В течение многих лет CNN доминировали в компьютерном зрении. Однако у них есть неотъемлемое ограничение: им сложно моделировать геометрические преобразования. Это связано с тем, что их основные строительные блоки, такие как слои свёртки и пулинга, имеют фиксированные геометрические структуры.

Новый модуль, **деформируемая свёртка**, дополняет стандартные местоположения выборки в CNN 2D-смещениями. Важно отметить, что эти смещения не фиксированы; они **_обучаются_** из предыдущих карт признаков с помощью дополнительных свёрточных слоёв. Это позволяет выборке сетки динамически деформироваться и адаптироваться к форме и масштабу объекта локально и плотно.

Идея адаптивной выборки из деформируемых свёрток была применена к механизму внимания Transformer. Результатом стал **Deformable DETR**[3].

Ключевое нововведение — **модуль деформируемого внимания**. Вместо вычисления весов внимания для всех пикселей на карте признаков этот модуль делает нечто более умное:

* Он учитывает только небольшое фиксированное количество ключевых точек выборки вокруг опорной точки.
* Как и в деформируемой свёртке, 2D-смещения для этих точек выборки обучаются из элемента запроса через линейную проекцию.
* Обходит необходимость в отдельной архитектуре FPN, поскольку его механизм внимания имеет встроенную возможность обрабатывать и объединять мультимасштабные функции напрямую.

Прорыв деформируемого внимания заключается в том, что он «уделяет внимание только небольшому набору ключевых точек выборки» [3] вокруг опорной точки, независимо от пространственного размера карт признаков. Анализ в статье показывает, что когда этот новый модуль применяется в энкодере (где количество запросов Nq равно пространственному размеру HW), сложность становится O(HWC2), что является линейным по отношению к пространственному размеру. Это единственное изменение делает вычислительно возможным обработку карт признаков высокого разрешения, значительно улучшая производительность при обнаружении мелких объектов.

#### Реальность времени: LW-DETR

Deformable DETR устранил проблемы со сходимостью и точностью, но чтобы конкурировать с моделями типа YOLO, ему нужно было быть быстрее. Здесь на помощь приходит **LW-DETR** (Light-Weight DETR) [4]. Его цель — создать архитектуру на основе Transformer, которая могла бы превзойти модели YOLO в обнаружении объектов в реальном времени.

Архитектура представляет собой простую стопку: кодировщик Vision Transformer (ViT), проектор и неглубокий декодер DETR. Они избавились от части архитектуры энкодер-декодер из фреймворка DETR и сохранили только часть декодера.

Чтобы достичь своей скорости, он использовал несколько ключевых методов повышения эффективности:

* **Деформируемое перекрёстное внимание:** декодер напрямую использует эффективный механизм деформируемого внимания из Deformable DETR, что имеет решающее значение для его производительности.
* **Чередующееся окно и глобальное внимание:** кодировщик ViT дорог. Чтобы снизить его сложность, LW-DETR заменяет некоторые дорогостоящие слои глобального самовнимания более дешёвыми слоями оконного самовнимания.
* **Более мелкий декодер:** стандартные варианты DETR часто используют 6 слоёв декодера. LW-DETR использует только 3, что значительно сокращает задержку.

Проектор в LW-DETR действует как ключевой мост, соединяя кодировщик Vision Transformer (ViT) с декодером DETR. Он построен с использованием **блока C2f**, который представляет собой эффективный свёрточный блок, используемый в модели YOLOv8. Этот блок обрабатывает функции и подготавливает их для механизма перекрёстного внимания декодера.

#### Сборка компонентов для RF-DETR

И это возвращает нас к RF-DETR [5]. Это не изолированный прорыв, а логический следующий шаг в этой эволюционной цепочке. В частности, они создали RF-DETR, объединив LW-DETR с предварительно обученным бэкендом DINOv2, как показано в этой строке кода. Это даёт модели исключительную способность адаптироваться к новым доменам на основе знаний, хранящихся в предварительно обученном бэкенде DINOv2.

Ключевое отличие от предыдущих моделей заключается в том, что Deformable DETR использует механизм мультимасштабного самовнимания, тогда как модель RF-DETR извлекает карты признаков изображения из одномасштабного бэкенда. Недавно команда, стоящая за моделью RF-DETR, внедрила сегментную головку, чтобы предоставлять маски в дополнение к ограничивающим рамкам, что делает её идеальным выбором и для задач сегментации.

#### Заключение

Оригинальный DETR произвёл революцию в конвейере обнаружения, убрав ручные компоненты, такие как NMS, но был непрактичен из-за медленной сходимости и квадратичной сложности. Deformable DETR предоставил ключевой архитектурный прорыв, заменив глобальное внимание эффективным механизмом адаптивной выборки, вдохновлённым деформируемыми свёртками. LW-DETR затем доказал, что эту эффективную архитектуру можно упаковать для обеспечения производительности в реальном времени, бросив вызов доминированию YOLO. RF-DETR представляет собой логический следующий шаг: он сочетает в себе эту высоко оптимизированную деформируемую архитектуру с необузданной мощью современного, самообучающегося бэкенда.

#### Список литературы

[1] End-to-End Object Detection with Transformers. Nicolas Carion et. al. 2020.
[2] Deformable Convolutional Networks. Jifeng Dai et. al. 2017.
[3] Deformable DETR: Deformable Transformers for End-to-End Object Detection. Xizhou Zhu et. al. 2020.
[4] LW-DETR: A Transformer Replacement to YOLO for Real-Time Detection. Qiang Chen et. al. 2024.
[5] https://github.com/roboflow/rf-detr/tree/develop

