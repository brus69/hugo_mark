---
title: "Оценка синтетических данных — Вопрос на миллион долларов | На пути к науке о данных"
date: "2025-11-19T23:13:09+0000"
draft: false
description: ""
h1: "Оценка синтетических данных — Вопрос на миллион долларов"
urldel: "https://towardsdatascience.com/evaluating-synthetic-data-the-million-dollar-question-a54701d1b621/"
---

### Генерация синтетических данных

Обычно мы создаём модель для наших реальных (или «наблюдаемых») данных, а затем используем эту модель для генерации синтетических данных. Эти наблюдаемые данные обычно собирают из реального опыта, например, измерения физических характеристик ирисов или детали о людях, которые не выполнили кредитные обязательства или приобрели какое-либо заболевание.

Мы можем представить наблюдаемые данные как взятые из некоторого «родительского распределения» — истинного базового распределения, из которого наблюдаемые данные являются случайной выборкой. Конечно, мы никогда не знаем это родительское распределение — его нужно оценить, и в этом цель нашей модели.

Но если наша модель может генерировать синтетические данные, которые можно считать случайной выборкой из того же родительского распределения, то мы выиграли: синтетические данные будут обладать теми же статистическими свойствами и закономерностями, что и наблюдаемые данные (_достоверность_); они будут так же полезны при выполнении таких задач, как регрессия или классификация (_полезность_); и, поскольку это случайная выборка, нет риска, что она идентифицирует наблюдаемые данные (_конфиденциальность_). Но как мы можем узнать, достигли ли мы этой неуловимой цели?

#### Часть 1 — Несколько простых экспериментов

Рассмотрим следующие два набора данных и попытаемся ответить на вопрос:

* Являются ли наборы данных случайными выборками из одного и того же родительского распределения, или один был получен из другого путём применения небольших случайных возмущений?

Наборы данных явно демонстрируют схожие статистические свойства, такие как маргинальные распределения и ковариации. Они также будут работать одинаково хорошо при выполнении задачи классификации, в которой классификатор, обученный на одном наборе данных, тестируется на другом.

Но предположим, мы построили данные из каждого набора на одном графике. Если наборы данных являются случайными выборками из одного и того же родительского распределения, мы интуитивно ожидаем, что точки из одного набора будут перемежаться с точками из другого таким образом, что в среднем точки из одного набора будут находиться так же близко к своим ближайшим соседям в этом наборе, как и к своим ближайшим соседям в другом наборе. Однако, если один набор данных является небольшим случайным возмущением другого, то точки из одного набора будут больше похожи на своих ближайших соседей в другом наборе, чем на своих ближайших соседей в том же наборе.

#### Тест на максимальную схожесть

* Для каждого набора данных рассчитайте схожесть между каждым экземпляром и его ближайшим соседом в том же наборе данных. Назовите эти «максимальные внутринаборные сходства». Если наборы данных имеют одинаковые характеристики распределения, то распределение внутринаборных сходств должно быть одинаковым для каждого набора данных. Теперь рассчитайте схожесть между каждым экземпляром одного набора данных и его ближайшим соседом в другом наборе данных и назовите эти «максимальные межнаборные сходства». Если распределение максимальных межнаборных сходств совпадает с распределением максимальных внутринаборных сходств, то наборы данных можно считать случайными выборками из одного и того же родительского распределения.

Для проведения теста каждый набор данных должен содержать одинаковое количество примеров.

#### Моделирование и синтез

Чтобы завершить эту первую часть истории, давайте создадим модель для набора данных и используем модель для генерации синтетических данных. Затем мы можем использовать тест на максимальную схожесть для сравнения синтетических и наблюдаемых наборов данных.

Набор данных слева на рисунке 4 ниже — это просто набор данных 1 из предыдущего примера. Набор данных справа (набор данных 3) — это синтетический набор данных. (Мы оценили распределение как смесь Гаусса, но это не важно).

**Рисунок 4.** Наблюдаемый набор данных (слева) и синтетический набор данных (справа).

Вот средние показатели схожести и гистограммы:

**Рисунок 5.** Распределение максимальных внутринаборных и межнаборных сходств для наборов данных 1 и 3.

Три средних значения идентичны до трёх знаков после запятой, а три гистограммы очень похожи. Поэтому, согласно тесту на максимальную схожесть, оба набора данных могут быть рассмотрены как случайные выборки из одного и того же родительского распределения.

#### Часть 2 — Реальные наборы данных, реальные генераторы

Набор данных, использованный в части 1, прост, и его можно легко смоделировать с помощью смеси гауссиан. Однако большинство реальных наборов данных гораздо сложнее. В этой части истории мы применим несколько генераторов синтетических данных к некоторым популярным наборам данных из реального мира.

Наши основные усилия будут направлены на сравнение распределений максимальных сходств внутри и между наблюдаемыми и синтетическими наборами данных, чтобы понять, насколько они могут считаться случайными выборками из одного и того же родительского распределения.

Шесть наборов данных происходят из репозитория UCI и являются популярными наборами данных, которые десятилетиями широко использовались в литературе по машинному обучению. Все они смешанного типа и были выбраны потому, что они различаются по соотношению категориальных и числовых признаков.

Шесть генераторов представляют основные подходы, используемые при генерации синтетических данных: на основе копул, на основе GAN, на основе VAE и подходы с использованием последовательного вменения. CopulaGAN, GaussianCopula, CTGAN и TVAE доступны в библиотеках _Synthetic Data Vault_, synthpop доступен как открытый исходный код R-пакета, а «UNCRi» относится к инструменту генерации синтетических данных, разработанному в рамках _Unified Numeric/Categorical Representation and Inference_ (UNCRi). Все генераторы использовались с настройками по умолчанию.

Таблица 1 показывает средние максимальные внутринаборные и межнаборные сходства для каждого генератора, применённого к каждому набору данных. Записи, выделенные красным цветом, — это те, в которых конфиденциальность была нарушена (т. е. среднее максимальное межнаборное сходство превышает среднее максимальное внутринаборное сходство на наблюдаемых данных). Записи, выделенные зелёным цветом, — это те, у которых среднее максимальное межнаборное сходство является самым высоким (не включая те, что выделены красным). Последний столбец показывает результат выполнения теста _Train on Synthetic, Test on Real_ (TSTR), где классификатор или регрессор обучается на синтетических примерах и тестируется на реальных (наблюдаемых) примерах.

**Таблица 1.** Средние максимальные сходства и результат TSTR для шести генераторов на шести наборах данных. Значения для TSTR — MAE для набора данных Boston Housing и AUC для всех остальных наборов данных.

Из таблицы видно, что для тех генераторов, которые не нарушали конфиденциальность, среднее максимальное межнаборное сходство очень близко к среднему максимальному внутринаборному сходству на наблюдаемых данных. Гистограммы показывают нам распределения этих максимальных сходств, и мы видим, что в большинстве случаев распределения явно схожи — особенно это касается набора данных Census Income.

#### Конфиденциальность

Только два из семи генераторов продемонстрировали проблемы с конфиденциальностью: synthpop и TVAE. Каждый из них нарушил конфиденциальность в трёх из шести наборов данных. В двух случаях, а именно TVAE на Cleveland Heart Disease и TVAE на Credit Approval, нарушение было особенно серьёзным.

#### Другие наблюдения и комментарии

Два генератора на основе GAN — CopulaGAN и CTGAN — стабильно показывали худшие результаты. Это было несколько удивительно, учитывая огромную популярность GAN.

Производительность GaussianCopula была посредственной на всех наборах данных, кроме Wisconsin Breast Cancer, для которого она достигла равного максимального среднего межнаборного сходства.

Генераторы, которые наиболее последовательно хорошо работают на всех наборах данных, — это synthpop и UNCRi, которые работают путём последовательного вменения. Это означает, что им нужно только оценить и выбрать образец из одномерного условного распределения (например, _P_(_x_ ₇|_x_ ₁, _x_ ₂, …)), и это обычно намного проще, чем моделирование и выборка из многомерного распределения (например, _P_(_x_ ₁, _x_ ₂, _x_ ₃, …)), что (неявно) делают GAN и VAE.

#### Заключение

Генерация синтетических данных — это новая и развивающаяся область, и хотя стандартных методов оценки пока нет, существует консенсус, что тесты должны охватывать достоверность, полезность и конфиденциальность. Но хотя каждая из этих характеристик важна, они не равнозначны. Например, синтетический набор данных может достичь хороших показателей по достоверности и полезности, но потерпеть неудачу по конфиденциальности.

Мы предлагаем следующую единую оценку качества синтетического набора данных:

Чем ближе это соотношение к 1 — не превышая 1 — тем выше качество синтетических данных. Конечно, это должно сопровождаться проверкой гистограмм.

