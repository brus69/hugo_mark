---
title: "Всегда ли Увеличение Объема Данных Приводит К Повышению Производительности? | На пути к науке о данных"
date: "2025-11-19T23:13:09+0000"
draft: true
description: ""
h1: "Всегда ли Увеличение Объема Данных Приводит К Повышению Производительности?"
urldel: "https://towardsdatascience.com/does-more-data-always-yield-better-performance/"
---

## В науке о данных мы стремимся улучшить недостаточно высокую производительность нашей модели, подгоняя её под имеющиеся данные

В науке о данных мы стремимся улучшить недостаточно высокую производительность нашей модели, подгоняя её под имеющиеся данные. Мы пробуем различные методы: от изменения сложности модели до обработки и предварительной подготовки данных. Однако чаще всего нам советуют _«просто»_ получить больше данных. Помимо того, что это проще сказать, чем сделать, возможно, нам стоит остановиться и подвергнуть сомнению общепринятое мнение.

> _Всегда ли добавление большего объёма данных приводит к повышению производительности?_

В этой статье давайте проверим эту пословицу, используя реальные данные и инструмент, который я создал для таких исследований. Мы прольём свет на тонкости, связанные со сбором и расширением данных, поставив под сомнение представление о том, что такие усилия автоматически улучшают производительность, и призывая к более осознанной и стратегической практике.

### Что означает «больше данных»?

Давайте сначала определим, что именно мы подразумеваем под «больше данных». В самом общем случае мы обычно представляем данные в виде таблицы. И когда предлагается идея получения дополнительных данных, в первую очередь приходит мысль о добавлении **дополнительных строк** в наш фрейм данных (то есть дополнительных точек данных или образцов).

Однако альтернативным подходом может быть **добавление дополнительных столбцов** (то есть дополнительных атрибутов или признаков). Первый подход расширяет данные вертикально, а второй — горизонтально.

Далее мы рассмотрим общие черты и особенности этих двух подходов.

Данные можно расширить, добавив больше образцов или больше столбцов. (Изображение автора)

### Случай 1: больше образцов

Давайте рассмотрим первый случай добавления большего количества образцов. Обязательно ли добавление большего количества образцов улучшает производительность модели?

Чтобы разобраться в этом, я создал инструмент, размещённый в пространстве HuggingFace, для решения этого вопроса. Этот инструмент позволяет пользователю экспериментировать с эффектами изменения набора атрибутов, размера выборки и/или сложности модели при анализе набора данных UCI Irvine – Predict Students’ Dropout and Academic Success [1] с помощью дерева решений. Хотя и инструмент, и набор данных предназначены для образовательных целей, мы всё равно сможем извлечь ценные идеи, которые выходят за рамки этого базового подхода.

…

### Случай 2: больше атрибутов

Теперь, говоря об атрибутах, давайте рассмотрим альтернативный сценарий, в котором вашему декану не удаётся получить больше записей студентов. Однако они приходят и говорят: «Эй, ты… Я не смог получить больше записей студентов… но я смог использовать SQL, чтобы получить больше атрибутов для ваших данных… Я уверен, что вы сможете улучшить свою производительность сейчас. Правда?… Правда?!»

Набор признаков против производительности: каждая вертикальная линия показывает переобучение дерева решений (800 образцов с перекрёстной проверкой гиперпараметров) с добавлением одного дополнительного атрибута. Некоторые атрибуты помогают (_Профессия матери_), в то время как другие вредят (_Профессия отца_ и _Пол_). Иногда большее количество столбцов может означать больше шума и больше способов переобучения. (Изображение автора, использующего набор данных UCI)

Что ж, давайте проверим это на практике. Рассмотрим пример, в котором мы постепенно добавляем больше атрибутов, **расширяя профиль студентов и включая их семейное положение, финансовый статус и статус иммигранта**. Каждый раз, когда мы добавляем атрибут, мы переобучаем дерево и оцениваем его производительность. Как видите, хотя некоторые приращения улучшают производительность, другие фактически ухудшают её. Но опять же, почему?

При более внимательном рассмотрении набора атрибутов мы обнаруживаем, что **не все атрибуты действительно содержат полезную информацию**. Реальный мир хаотичен… Некоторые атрибуты (например, _пол_) могут создавать шум или ложные корреляции в обучающем наборе данных, которые не будут хорошо обобщаться на тестовом наборе (переобучение).

Кроме того, хотя общепринятая мудрость гласит, что при добавлении большего объёма данных вы должны увеличивать сложность модели, такая практика не всегда приводит к наилучшим результатам. Иногда при добавлении атрибута **снижение сложности модели может помочь с переобучением** (например, когда в смесь был добавлен _курс_).

### Заключение

Отойдя на шаг назад и взглянув на общую картину, мы увидим, что, хотя сбор большего объёма данных — это благородная цель, мы должны быть осторожны, чтобы не предполагать автоматически, что производительность улучшится. Здесь действуют две силы: насколько хорошо модель соответствует обучающим данным и насколько надёжно это соответствие распространяется на невидимые данные.

Давайте суммируем, как каждый тип «большего объёма данных» влияет на эти силы — в зависимости от того, является ли добавленная данные хорошими (представительными, последовательными, информативными) или плохими (смещёнными, шумными, непоследовательными):

| **Если качество данных хорошее** …| **Если качество данных плохое** …  
|---|---|
| **Больше образцов (строк)** | • Ошибочная **подготовка может немного возрасти** (больше вариаций усложняет подгонку).  • **Ошибка тестирования** обычно **снижается**. Модель становится более стабильной и уверенной. | • Ошибочная **подготовка может колебаться** из-за противоречивых примеров.  • **Ошибка тестирования** часто **возрастает**. |
| **Больше атрибутов (столбцов)** | • Ошибочная **подготовка** обычно **снижается** (больше сигналов приводит к более богатому представлению).  • **Ошибка тестирования снижается**, поскольку атрибуты кодируют истинные и обобщаемые закономерности. | • Ошибочная **подготовка** обычно **снижается** (модель запоминает шумные закономерности).  • **Ошибка тестирования возрастает** из-за ложных корреляций. |

Обобщение — это не только количество, но и качество и правильный уровень сложности модели.

В заключение, в следующий раз, когда кто-то предложит вам «просто» получить больше данных, чтобы волшебным образом повысить точность, обсудите с ним тонкости такого плана. Поговорите о характеристиках полученных данных с точки зрения природы, размера и качества. Укажите на нюансы взаимодействия между данными и сложностью модели. Это поможет сделать их усилия более полезными!

### Уроки, которые нужно усвоить:

* **Всякий раз, когда это возможно, не верьте на слово другим (или мне). Экспериментируйте сами!**
* **Добавляя больше точек данных** для обучения, спросите себя: **представляют ли эти выборки явление, которое вы моделируете**? Показывают ли они модели более интересные реалистичные случаи? Или они смещены и/или непоследовательны?
* **Добавляя больше атрибутов**, спросите себя: **гипотетически ли эти атрибуты содержат информацию**, которая повышает нашу способность делать более точные прогнозы, или это в основном шум?
* В конечном счёте **проводите настройку гиперпараметров и правильную валидацию**, чтобы устранить сомнения при оценке того, насколько информативны новые обучающие данные.

### Попробуйте сами!

Если вы хотите самостоятельно изучить динамику, показанную в этой статье, **я разместил интерактивный инструмент здесь**. Экспериментируя, настраивая размер выборки, количество атрибутов и/или глубину модели, вы увидите влияние этих настроек на производительность модели. Такие эксперименты обогащают вашу перспективу и понимание механизмов, лежащих в основе науки о данных и аналитики.

### Ссылки:

[1] M.V.Martins, D. Tolledo, J. Machado, L. M.T. Baptista, V.Realinho. (2021) “Early prediction of student’s performance in higher education: a case study” Trends and Applications in Information Systems and Technologies, vol.1, in Advances in Intelligent Systems and Computing series. Springer. DOI: 10.1007/978-3-030-72657-7_16. Этот набор данных лицензирован в соответствии с лицензией Creative Commons Attribution 4.0 International (CC BY 4.0). Это позволяет делиться наборами данных и адаптировать их для любых целей при условии, что соответствующим данным будет предоставлен соответствующий кредит.

[2] Z. Liu and K. He, _A Decade’s Battle on Dataset Bias: Are We There Yet?_ (2024), arXiv: https://arxiv.org/abs/2403.08632

