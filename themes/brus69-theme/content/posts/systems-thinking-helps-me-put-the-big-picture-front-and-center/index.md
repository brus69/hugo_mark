---
title: "\"Системное мышление помогает мне видеть общую картину в целом\" | На пути к науке о данных"
date: "2025-11-19T23:13:09+0000"
draft: false
description: ""
h1: "“Системное мышление помогает мне видеть общую картину в центре внимания”"
urldel: "https://towardsdatascience.com/systems-thinking-helps-me-put-the-big-picture-front-and-center/"
---

### В серии «В центре внимания автора» редакторы TDS беседуют с представителями нашего сообщества об их карьере в области науки о данных и искусственного интеллекта, их творчестве и источниках вдохновения. Сегодня мы рады поделиться с вами беседой с Шуай Гоу.

Шуай — исследователь в области промышленного искусственного интеллекта, работающий с физикой, данными и машинным обучением для решения реальных задач в инженерии, безопасности и интеллектуальных системах. Он имеет докторскую степень на стыке вычислительной механики и машинного обучения. Его работа охватывает различные темы, включая обнаружение аномалий, цифровые двойники, обучение с учётом физических данных и приложения LLM/агентских систем.

**Ваш материал LangGraph знакомит читателя с процессом создания исследовательского агента глубокого обучения. Когда вы фактически попробовали реализовать его от начала до конца, что удивило вас больше всего, и что вы сделали бы по-другому в следующий раз?**

Я бы сказал, что больше всего меня удивило то, как легко агент глубокого исследования может ошибаться при выполнении полного цикла работы. Этот цикл «сгенерировать запрос → поиск → размышление → повторить» прекрасно выглядит на бумаге, но быстро разваливается. Есть две основные проблемы, которые я отчётливо помню. Во-первых, время от времени агент начинает путать то, что он нашёл, с тем, что он помнит из предварительного обучения. Это не идеально, поскольку я хочу, чтобы LLM синтезировали информацию и выявляли пробелы в знаниях, полностью полагаясь при этом на веб-поиск для обоснования ответа.

Ещё одна проблема, которая постоянно доставляет мне головную боль, — это загрязнение информации, то есть ситуация, когда поиск выдаёт похожие материалы, но модель воспринимает их как то, что вы просили. Например, я однажды тестировал агента глубокого исследования, изучая конкретный отчёт об ошибке (скажем, проблема № 4521 в кодовой базе), и поиск возвращал контент, относящийся к проблеме № 4522, и начинал смешивать их симптомы, как будто это одна и та же проблема.

Помимо этих двух основных проблем, я также столкнулся с трудностями в обработке противоречивой информации и определении достаточности для завершения глубокого исследования. Ни одну из этих проблем нельзя решить, просто добавив больше результатов поиска или выполнив больше итераций.

Для меня ключевым осознанием стало то, что ограничения так же важны, если не более, чем архитектура агента, если мы хотим выйти за рамки «просто демонстрации» и создать систему, которая действительно работает в производственной среде. Я думаю, что подход «разработки на основе тестирования» здесь вполне уместен: определите, как выглядит «хорошо», прежде чем строить. В следующий раз я бы начал с определения чётких правил, а затем построил архитектуру агента с учётом этих ограничений.

**Вы писали, что аналитический искусственный интеллект (SQL/BI + классический ML) никуда не денется только потому, что агенты в моде. Если бы вы разрабатывали современный стек данных сегодня, какую работу вы бы поручили агентам, а что оставили бы в аналитике?**

Аналитический искусственный интеллект воспроизводим и численно точен. С другой стороны, агенты на основе LLM хорошо справляются с обработкой неструктурированного контекста, переводом результатов и общением с людьми. Для распределения задач между аналитическим ИИ и агентским ИИ я бы сказал, что если задача больше ориентирована на количественные показатели, я бы выбрал аналитический ИИ; но если она больше ориентирована на качественные показатели, например, синтез, сторителлинг или суждения, я бы рассмотрел LLM/агентов как более подходящую альтернативу.

Мы можем рассмотреть конкретную проблему создания системы прогнозирования оттока клиентов. На высоком уровне она обычно включает два шага: выявление клиентов, подверженных риску, и принятие мер в отношении них. Для первого шага по выявлению клиентов, подверженных риску, я бы опирался на аналитический ИИ для разработки информативных функций, обучения моделей градиентного бустинга на исторических данных о поведении и использования обученных моделей для расчёта баллов склонности к оттоку. Кроме того, я бы также провёл анализ SHAP, чтобы получить оценки важности функций для объяснения прогноза. Каждый шаг точен и воспроизводим, и существует множество лучших практик, доступных для получения точных и надёжных результатов.

Но затем наступает интересная часть: что вы на самом деле делаете с этими прогнозами? Здесь-то и могут взять верх агенты на основе LLM. Они могут составлять персонализированные электронные письма для удержания клиентов, используя историю клиента, возможно, предлагать релевантные функции продукта, которые они ещё не пробовали, и корректировать тон в зависимости от того, как проходили их прошлые обращения в службу поддержки. Здесь нет математики. Просто разговор в умном контексте.

**Какой навык вы приобрели в начале, который сейчас даёт вам преимущество, поскольку инструменты искусственного интеллекта становятся всё более совершенными?**

Системное мышление.

Для меня системное мышление — это, по сути, вопрос о том, как разложить системы на компоненты. Как разные компоненты взаимодействуют друг с другом? Каковы точки передачи? Где находятся петли обратной связи? Если я изменю это, что ещё изменится?

Я приобрёл это в университете. Я специализировался в аэрокосмической инженерии с упором на проектирование авиационных двигателей. Дело в том, что в реактивных двигателях всё влияет на всё, и изучение этого действительно помогло мне развить три привычки: разложить систему, определить чистые интерфейсы и всегда искать эффекты связи.

Это правда, что инструменты искусственного интеллекта становятся всё более совершенными, например, у нас появились более совершенные помощники по кодированию, более эффективные конвейеры RAG или LLM, которые могут обрабатывать более длинный контекст, но большинство достижений происходит в узких срезах. Вместо того чтобы всегда гнаться за самым горячим инструментом и пытаться каким-то образом внедрить его в свою существующую работу, системное мышление помогает мне сосредоточиться на общей картине. Для приложения LLM я бы всегда начинал с набросков компонентов, определения взаимодействия и входов/выходов между компонентами, следил за добавлением проверок и ограничений, а затем менял компоненты по мере улучшения инструментов.

На самом деле, создание приложений LLM напоминает мне проектирование реактивных двигателей: новые технологии приходят и уходят, но солидная системная конструкция увеличивает ценность.

**Если вы отойдёте от дел, какая часть науки о данных или искусственного интеллекта меняется слишком быстро прямо сейчас, а какая меняется недостаточно быстро?**

Я думаю, что мультиагентные системы искусственного интеллекта определённо являются одной из самых горячих областей, которые развиваются очень быстро. Мы видим причудливые демонстрации (будь то помощник по кодированию или исследовательский помощник) то и дело. Постоянно появляются новые открытые фреймворки, которые позволяют разработчикам эффективно создавать свои собственные мультиагентные приложения. Всё это очень увлекательно. Но вот в чём дело: мы выпускаем эти сложные системы гораздо быстрее, чем понимаем, как они будут вести себя на практике?

Вот где я вижу пробел: весь «защитный» слой вокруг этих мультиагентных систем развивается недостаточно быстро. Чтобы решить эту проблему, мы можем (и, вероятно, должны) относиться к этим мультиагентным системам так же, как и к любой другой промышленной системе. В обрабатывающей промышленности принято использовать подходы, основанные на данных, для проектирования систем, управления, мониторинга состояния и анализа неисправностей. Этот же подход может быть полезен и для мультиагентных систем. Например, как насчёт того, чтобы использовать байесовскую оптимизацию для проектирования мультиагентной архитектуры? Как насчёт использования обнаружения аномалий на основе машинного обучения для мониторинга производительности агентов и выявления угроз безопасности?

Хорошая новость заключается в том, что наметился импульс. Мы видим платформы наблюдаемости для LLM, фреймворки оценки и т. д., и они закладывают основу для применения этих промышленных методов, основанных на данных. Я вижу много возможностей в этой области, и это то, что меня волнует: шанс привнести строгость промышленных систем в агентский ИИ и сделать эти инструменты надёжными и заслуживающими доверия.

